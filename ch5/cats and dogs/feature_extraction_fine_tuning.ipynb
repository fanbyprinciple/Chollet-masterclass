{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1214 08:17:21.575314  8400 deprecation_wrapper.py:119] From C:\\installs\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'Z:\\\\codeplay\\\\Chollet-masterclass\\\\ch5\\\\cats and dogs\\\\cat_and_dogs_small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 16,812,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name== 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else :\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',optimizer = optimizers.RMSprop(lr=2e-5),metrics = ['acc']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1214 08:43:12.685050  8400 deprecation_wrapper.py:119] From C:\\installs\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 92s 922ms/step - loss: 0.4947 - acc: 0.7490 - val_loss: 0.1905 - val_acc: 0.7930\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 49s 494ms/step - loss: 0.3288 - acc: 0.8635 - val_loss: 0.2582 - val_acc: 0.8730\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 50s 499ms/step - loss: 0.2871 - acc: 0.8710 - val_loss: 0.3310 - val_acc: 0.9050\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 50s 498ms/step - loss: 0.2613 - acc: 0.8890 - val_loss: 0.1052 - val_acc: 0.9220\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 51s 512ms/step - loss: 0.2354 - acc: 0.9030 - val_loss: 0.1849 - val_acc: 0.9240\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 50s 502ms/step - loss: 0.2158 - acc: 0.9105 - val_loss: 0.5082 - val_acc: 0.9240\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 51s 511ms/step - loss: 0.1996 - acc: 0.9180 - val_loss: 0.1394 - val_acc: 0.9310\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 50s 496ms/step - loss: 0.1924 - acc: 0.9255 - val_loss: 0.1184 - val_acc: 0.9250\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 49s 492ms/step - loss: 0.1801 - acc: 0.9245 - val_loss: 0.1128 - val_acc: 0.9350\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 50s 497ms/step - loss: 0.1739 - acc: 0.9290 - val_loss: 0.0263 - val_acc: 0.9370\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 50s 503ms/step - loss: 0.1553 - acc: 0.9390 - val_loss: 0.1026 - val_acc: 0.9330\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 51s 514ms/step - loss: 0.1592 - acc: 0.9340 - val_loss: 0.1593 - val_acc: 0.9320\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 49s 485ms/step - loss: 0.1422 - acc: 0.9415 - val_loss: 0.0737 - val_acc: 0.9220\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 49s 492ms/step - loss: 0.1471 - acc: 0.9405 - val_loss: 0.0454 - val_acc: 0.9410\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 49s 487ms/step - loss: 0.1159 - acc: 0.9550 - val_loss: 0.3372 - val_acc: 0.9280\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 49s 487ms/step - loss: 0.1110 - acc: 0.9550 - val_loss: 0.2745 - val_acc: 0.9240\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 49s 490ms/step - loss: 0.1135 - acc: 0.9515 - val_loss: 0.0214 - val_acc: 0.9390\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 50s 497ms/step - loss: 0.1163 - acc: 0.9520 - val_loss: 6.3852e-04 - val_acc: 0.9320\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 42s 419ms/step - loss: 0.1019 - acc: 0.9620 - val_loss: 0.2164 - val_acc: 0.9380\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0938 - acc: 0.9640 - val_loss: 0.1545 - val_acc: 0.9290\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.1009 - acc: 0.9560 - val_loss: 0.0858 - val_acc: 0.9310\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.1057 - acc: 0.9575 - val_loss: 0.1715 - val_acc: 0.9320\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0827 - acc: 0.9635 - val_loss: 0.0439 - val_acc: 0.9290\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0906 - acc: 0.9655 - val_loss: 0.0323 - val_acc: 0.9340\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0854 - acc: 0.9685 - val_loss: 0.1555 - val_acc: 0.9270\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0785 - acc: 0.9695 - val_loss: 0.3348 - val_acc: 0.9370\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0718 - acc: 0.9715 - val_loss: 0.0013 - val_acc: 0.9270\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0905 - acc: 0.9635 - val_loss: 0.0924 - val_acc: 0.9340\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0711 - acc: 0.9700 - val_loss: 0.1589 - val_acc: 0.9130\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0678 - acc: 0.9755 - val_loss: 0.2822 - val_acc: 0.9390\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0630 - acc: 0.9765 - val_loss: 0.3644 - val_acc: 0.9330\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0734 - acc: 0.9745 - val_loss: 0.1140 - val_acc: 0.9340\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0564 - acc: 0.9810 - val_loss: 0.2186 - val_acc: 0.9370\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0581 - acc: 0.9815 - val_loss: 0.0038 - val_acc: 0.9340\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0505 - acc: 0.9820 - val_loss: 0.4394 - val_acc: 0.9420\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0622 - acc: 0.9785 - val_loss: 0.0218 - val_acc: 0.9380\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0461 - acc: 0.9835 - val_loss: 0.5256 - val_acc: 0.9380\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0585 - acc: 0.9815 - val_loss: 0.1290 - val_acc: 0.9440\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0509 - acc: 0.9805 - val_loss: 0.0457 - val_acc: 0.9340\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0480 - acc: 0.9825 - val_loss: 0.1619 - val_acc: 0.9340\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0505 - acc: 0.9850 - val_loss: 0.1550 - val_acc: 0.9410\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0390 - acc: 0.9875 - val_loss: 0.0042 - val_acc: 0.9430\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0436 - acc: 0.9815 - val_loss: 0.3974 - val_acc: 0.9360\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0440 - acc: 0.9865 - val_loss: 0.3698 - val_acc: 0.9360\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0493 - acc: 0.9825 - val_loss: 0.0187 - val_acc: 0.9440\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0369 - acc: 0.9835 - val_loss: 1.3322 - val_acc: 0.9310\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0462 - acc: 0.9840 - val_loss: 0.2329 - val_acc: 0.9390\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0404 - acc: 0.9835 - val_loss: 0.1291 - val_acc: 0.9430\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0283 - acc: 0.9875 - val_loss: 1.4519 - val_acc: 0.9400\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0385 - acc: 0.9855 - val_loss: 0.6630 - val_acc: 0.9290\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0394 - acc: 0.9840 - val_loss: 0.2089 - val_acc: 0.9360\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0356 - acc: 0.9900 - val_loss: 0.0328 - val_acc: 0.9420\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0405 - acc: 0.9850 - val_loss: 0.5025 - val_acc: 0.9430\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0535 - acc: 0.9835 - val_loss: 0.0012 - val_acc: 0.9110\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0379 - acc: 0.9870 - val_loss: 0.7503 - val_acc: 0.9370\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0311 - acc: 0.9890 - val_loss: 0.2682 - val_acc: 0.9290\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0426 - acc: 0.9845 - val_loss: 0.3016 - val_acc: 0.9410\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0299 - acc: 0.9895 - val_loss: 0.9292 - val_acc: 0.9340\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0348 - acc: 0.9880 - val_loss: 0.3011 - val_acc: 0.9360\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0381 - acc: 0.9890 - val_loss: 0.1097 - val_acc: 0.9320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0390 - acc: 0.9875 - val_loss: 0.6235 - val_acc: 0.9320\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0301 - acc: 0.9880 - val_loss: 0.1957 - val_acc: 0.9390\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0302 - acc: 0.9890 - val_loss: 1.0218 - val_acc: 0.9390\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0340 - acc: 0.9905 - val_loss: 0.4983 - val_acc: 0.9340\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0259 - acc: 0.9895 - val_loss: 3.8350e-04 - val_acc: 0.9130\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0271 - acc: 0.9905 - val_loss: 0.1264 - val_acc: 0.9290\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0305 - acc: 0.9905 - val_loss: 0.1019 - val_acc: 0.9440\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 0.0096 - acc: 0.9970 - val_loss: 0.2346 - val_acc: 0.9390\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0371 - acc: 0.9890 - val_loss: 0.2313 - val_acc: 0.9410\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0219 - acc: 0.9920 - val_loss: 0.7506 - val_acc: 0.9400\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0229 - acc: 0.9910 - val_loss: 1.0807 - val_acc: 0.9090\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0301 - acc: 0.9910 - val_loss: 0.4858 - val_acc: 0.9250\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0318 - acc: 0.9890 - val_loss: 0.5249 - val_acc: 0.9380\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0277 - acc: 0.9935 - val_loss: 0.1166 - val_acc: 0.9370\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0236 - acc: 0.9920 - val_loss: 0.0438 - val_acc: 0.9390\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0191 - acc: 0.9935 - val_loss: 0.1692 - val_acc: 0.9440\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0353 - acc: 0.9900 - val_loss: 0.3865 - val_acc: 0.9290\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0186 - acc: 0.9945 - val_loss: 0.5708 - val_acc: 0.9450\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0227 - acc: 0.9905 - val_loss: 0.0714 - val_acc: 0.9420\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0267 - acc: 0.9900 - val_loss: 0.3659 - val_acc: 0.9400\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0207 - acc: 0.9920 - val_loss: 0.0719 - val_acc: 0.9400\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0222 - acc: 0.9935 - val_loss: 1.4706 - val_acc: 0.9450\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0352 - acc: 0.9895 - val_loss: 1.3863 - val_acc: 0.9360\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0262 - acc: 0.9910 - val_loss: 5.0951e-04 - val_acc: 0.9280\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0189 - acc: 0.9930 - val_loss: 0.3078 - val_acc: 0.9370\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0211 - acc: 0.9925 - val_loss: 0.3467 - val_acc: 0.9390\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0159 - acc: 0.9935 - val_loss: 0.1191 - val_acc: 0.9290\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0219 - acc: 0.9925 - val_loss: 0.3329 - val_acc: 0.9330\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0186 - acc: 0.9945 - val_loss: 0.3072 - val_acc: 0.9340\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0162 - acc: 0.9945 - val_loss: 0.0047 - val_acc: 0.9410\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0120 - acc: 0.9955 - val_loss: 0.1419 - val_acc: 0.9170\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0249 - acc: 0.9915 - val_loss: 0.8555 - val_acc: 0.9400\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0396 - acc: 0.9905 - val_loss: 0.2297 - val_acc: 0.9400\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0153 - acc: 0.9965 - val_loss: 1.4270 - val_acc: 0.9400loss: 0.01\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0193 - acc: 0.9950 - val_loss: 1.7865 - val_acc: 0.9340\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0190 - acc: 0.9945 - val_loss: 6.2227e-04 - val_acc: 0.9330\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0211 - acc: 0.9940 - val_loss: 0.0026 - val_acc: 0.9400\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0093 - acc: 0.9980 - val_loss: 0.0011 - val_acc: 0.9370\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0121 - acc: 0.9970 - val_loss: 0.1178 - val_acc: 0.9400\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0234 - acc: 0.9930 - val_loss: 0.3204 - val_acc: 0.9360\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=100,\n",
    "    validatibon_data= validation_generator,\n",
    "    validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def smooth_curve(points, factor=0.8):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1- factor) )\n",
    "        else :\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-9ca5cf9eccea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmooth_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Smoothed training acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmooth_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Smoothed validation acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training and validation accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(epochs, smooth_curve(acc), 'bo', label='Smoothed training acc')\n",
    "plt.plot(epochs, smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
    "plt.title('training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, smooth_curve(loss), 'bo',label='smoothed training loss')\n",
    "plt.plot(epochs, smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
