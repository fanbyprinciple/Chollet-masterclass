{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset\n",
    "\n",
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels),(test_data,test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for data\n",
    "\n",
    "def vectorize_sequences(sequences,dimension= 10000):\n",
    "    results =  np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for labels\n",
    "\n",
    "def to_one_hot(labels, dimension=46):\n",
    "    results =np.zeros((len(labels),dimension))\n",
    "    for i ,label in enumerate(labels):\n",
    "        results[i,label] = 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)\n",
    "\n",
    "## built in way , use to_categorical function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you buildthe modelit important never to have a layer having fewer dimension tah final layer\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the validation from train and test_data\n",
    "\n",
    "x_val =x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10000)\n",
      "(1000, 46)\n",
      "(7982, 10000)\n",
      "(7982, 46)\n"
     ]
    }
   ],
   "source": [
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1103 09:04:03.918795  3184 deprecation_wrapper.py:119] From C:\\installs\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 2s 258us/step - loss: 2.6212 - accuracy: 0.5452 - val_loss: 1.7428 - val_accuracy: 0.6580\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 125us/step - loss: 1.4085 - accuracy: 0.7041 - val_loss: 1.3055 - val_accuracy: 0.7060\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 117us/step - loss: 1.0494 - accuracy: 0.7725 - val_loss: 1.1232 - val_accuracy: 0.7570\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 117us/step - loss: 0.8318 - accuracy: 0.8193 - val_loss: 1.0277 - val_accuracy: 0.7690\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 0.6645 - accuracy: 0.8602 - val_loss: 0.9574 - val_accuracy: 0.7870\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 120us/step - loss: 0.5315 - accuracy: 0.8909 - val_loss: 0.9077 - val_accuracy: 0.8040\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 123us/step - loss: 0.4296 - accuracy: 0.9090 - val_loss: 0.8980 - val_accuracy: 0.8100\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 120us/step - loss: 0.3489 - accuracy: 0.9270 - val_loss: 0.8772 - val_accuracy: 0.8150\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 134us/step - loss: 0.2907 - accuracy: 0.9375 - val_loss: 0.8913 - val_accuracy: 0.8130\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 134us/step - loss: 0.2432 - accuracy: 0.9429 - val_loss: 0.8821 - val_accuracy: 0.8160\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 133us/step - loss: 0.2131 - accuracy: 0.9486 - val_loss: 0.8889 - val_accuracy: 0.8210\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 125us/step - loss: 0.1862 - accuracy: 0.9503 - val_loss: 0.9020 - val_accuracy: 0.8200\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 0.1672 - accuracy: 0.9533 - val_loss: 0.9750 - val_accuracy: 0.8050\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 124us/step - loss: 0.1528 - accuracy: 0.9538 - val_loss: 0.9526 - val_accuracy: 0.8070\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 125us/step - loss: 0.1404 - accuracy: 0.9555 - val_loss: 0.9546 - val_accuracy: 0.8130\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 130us/step - loss: 0.1306 - accuracy: 0.9564 - val_loss: 0.9875 - val_accuracy: 0.8170\n",
      "Epoch 17/20\n",
      "1536/7982 [====>.........................] - ETA: 0s - loss: 0.1331 - accuracy: 0.9531"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs = 20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
