{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm works on what is called the language model\n",
    "\n",
    "# a parameter creatively named as softmax temperature characterises the entropy of probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def reweight_distribution(original_distribution, temperature=0.5):\n",
    "    distribution = np.log(original_distribution)/ temperature\n",
    "    distribution = np.exp(distribution)\n",
    "    return distribution / np.sum(distribution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "606208/600901 [==============================] - 2s 3us/step\n",
      "600901\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "path = keras.utils.get_file('neitzche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences:  200281\n",
      "Unique:  59\n",
      "14\n",
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, '8': 18, '9': 19, ':': 20, ';': 21, '=': 22, '?': 23, '[': 24, ']': 25, '_': 26, 'a': 27, 'b': 28, 'c': 29, 'd': 30, 'e': 31, 'f': 32, 'g': 33, 'h': 34, 'i': 35, 'j': 36, 'k': 37, 'l': 38, 'm': 39, 'n': 40, 'o': 41, 'p': 42, 'q': 43, 'r': 44, 's': 45, 't': 46, 'u': 47, 'v': 48, 'w': 49, 'x': 50, 'y': 51, 'z': 52, '¤': 53, '¦': 54, '©': 55, '«': 56, 'ã': 57, '†': 58}\n"
     ]
    }
   ],
   "source": [
    "maxlen= 60\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text)-maxlen, step):\n",
    "    sentences.append(text[i:i+maxlen])\n",
    "    next_chars.append(text[i+maxlen])\n",
    "\n",
    "print('Number of sequences: ', len(sentences))\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique: ', len(chars))\n",
    "\n",
    "print(chars.index('4'))\n",
    "\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "print(char_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "200281\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "# print(\"x: \", x)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "# print(\"y: \", y)\n",
    "\n",
    "for i,sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i,t,char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200281\n",
      "200281\n",
      "200281\n",
      "200281\n"
     ]
    }
   ],
   "source": [
    "print(len(x[::]))\n",
    "print(len(x))\n",
    "print(len(x[:]))\n",
    "      \n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen,len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation = 'softmax'))\n",
    "          \n",
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer=optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 128)               96256     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 59)                7611      \n",
      "=================================================================\n",
      "Total params: 103,867\n",
      "Trainable params: 103,867\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps to generate words given a trained model and seed text snippet\n",
    "# 1. Draw from the model a probability dist for next character\n",
    "# 2. Reweight distribution to certain temperature\n",
    "# 3. sample next character at random according to reqeighted distribtion\n",
    "# 4. add the new character at the end of the available text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to sample next character given model's prediction\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)/ temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds/np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1,preds,1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 79s 394us/step - loss: 1.5324\n",
      "Generating with seed:  cacy, its gram of salt and sprinkling\n",
      "of ambergris from a hi\n",
      "Temperature:  0.2\n",
      "cacy, its gram of salt and sprinkling\n",
      "of ambergris from a history of the same the supposing of the stands of the spirit of the world of the world of the world of the spirit of the spirit of the sense of the same that it is a states of the world of the individual the war the origin of the senses of the world of the sense of the spirit of the supposing of the world of the world of the world of the wastence of the sense of the standing of the sense of the souTemperature:  0.5\n",
      "astence of the sense of the standing of the sense of the soul souls of the consider of a germans in the object of men which is not the disposing of the spirit of more in the have breaks and in the soul in his new one is worances of his science of the will in the still as a  nothing and in the origin of podity which a states in an art of dorant and a some the wastes, what is the methided of general that he is the origin of man who is wish men to conscreatioTemperature:  1.0\n",
      " that he is the origin of man who is wish men to conscreation of liupcatipuation and brooductugant! the conscituishing, and wasted \"of honors, tood by theighter exposience what his opprinting\n",
      "sincered who philosophisant with pertain one you promising that with the doy self\n",
      "duminent ent in anterrate of porisy whenout in the worlderomonary of\n",
      "aluke, and\n",
      "been \n",
      "\n",
      "very cerceatianing and evendows anath\" the preseriation, may present that be the consequence of manTemperature:  1.2\n",
      "the preseriation, may present that be the consequence of many fnexting\n",
      "which not fally , but wit releges amoance, athogeound.--whether taegar out of de chere inleising sue die\n",
      "\"tenperin liw of a more-trut pemplemt\" of egainched; bay a made\n",
      "the me, aigen altegh righty, as light it takelops, of tal estlfulacy, that other. i wor\n",
      "fgen utility.\n",
      "\n",
      "222mpain tikes whae:\n",
      "\n",
      "kposir hamps, and chleasationuails, without the our1\" the cupin of dig\"nct,\n",
      "whos to\n",
      "shy\n",
      "greatunepoch 2\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 84s 421us/step - loss: 1.4851\n",
      "Generating with seed:  he moral, the apparently miraculous may be traced successful\n",
      "epoch 3\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 76s 380us/step - loss: 1.4556\n",
      "Generating with seed:  nt?\n",
      "and granted that your imperative, \"living according to n\n",
      "epoch 4\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 78s 388us/step - loss: 1.4319\n",
      "Generating with seed:  d partly on the\n",
      "surprising development and refined requireme\n",
      "epoch 5\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 77s 384us/step - loss: 1.4138\n",
      "Generating with seed:  ld of\n",
      "conception, and lift us, at least for a time, above th\n",
      "epoch 6\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 78s 388us/step - loss: 1.4001\n",
      "Generating with seed:  t in denouncing the advocate of god, the theologian or\n",
      "the t\n",
      "epoch 7\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 82s 409us/step - loss: 1.3895\n",
      "Generating with seed:  his point of view there is perhaps much\n",
      "more in the concepti\n",
      "epoch 8\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 80s 401us/step - loss: 1.3790\n",
      "Generating with seed:  sen in der welt: the above translation may seem\n",
      "too literal \n",
      "epoch 9\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 83s 415us/step - loss: 1.3693\n",
      "Generating with seed:   of evil origin. it is the master stroke of religions and me\n",
      "epoch 10\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 80s 402us/step - loss: 1.3609\n",
      "Generating with seed:  as he must take the consequences\n",
      "of his fault to a greater e\n",
      "epoch 11\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 84s 418us/step - loss: 1.3542\n",
      "Generating with seed:  a classic reputation but here it is expedient to break off m\n",
      "epoch 12\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 72s 358us/step - loss: 1.3482\n",
      "Generating with seed:  ally, one may say that woman would\n",
      "not have the genius for a\n",
      "epoch 13\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 72s 358us/step - loss: 1.3410\n",
      "Generating with seed:  promotes his own salvation; when, for example, he builds a\n",
      "c\n",
      "epoch 14\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 72s 358us/step - loss: 1.33591s - \n",
      "Generating with seed:  t he tells, insert twenty more).\n",
      "therefore, because in plain\n",
      "epoch 15\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 72s 361us/step - loss: 1.3318\n",
      "Generating with seed:  ss, death\n",
      "itself, is a consequence of magical influences. in\n",
      "epoch 16\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - ETA: 0s - loss: 1.325 - 72s 358us/step - loss: 1.3251\n",
      "Generating with seed:  antly, or vice versa.\" to wait\n",
      "in such circumstances would b\n",
      "epoch 17\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 72s 357us/step - loss: 1.3204\n",
      "Generating with seed:  t also in their virtues; or whether they were\n",
      "accustomed to \n",
      "epoch 18\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 72s 357us/step - loss: 1.3181\n",
      "Generating with seed:  hes to take revenge, with others to conceal himself, with ot\n",
      "epoch 19\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 72s 357us/step - loss: 1.3151\n",
      "Generating with seed:  ave the right\n",
      "out of one's own experience--experience, as it\n",
      "epoch 20\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 72s 358us/step - loss: 1.3124\n",
      "Generating with seed:   in which \"the exploiting character\" is to be absent--that s\n",
      "epoch 21\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 73s 364us/step - loss: 1.3098\n",
      "Generating with seed:  kes even their own aspect endurable to them, it\n",
      "operates upo\n",
      "epoch 22\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 72s 358us/step - loss: 1.3057\n",
      "Generating with seed:   kind continues when the discovery\n",
      "has been made that in usi\n",
      "epoch 23\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 74s 367us/step - loss: 1.3011\n",
      "Generating with seed:   in\n",
      "a supermoral sense. to be sure, one must not resign ones\n",
      "epoch 24\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 84s 417us/step - loss: 1.2998\n",
      "Generating with seed:   right: that is, does what seems to him\n",
      "good (advantageous) \n",
      "epoch 25\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 82s 408us/step - loss: 1.2967\n",
      "Generating with seed:  en long stored up and accumulated,\n",
      "there the will--uncertain\n",
      "epoch 26\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 82s 410us/step - loss: 1.2953\n",
      "Generating with seed:  y as\n",
      "a peasant or a corps-student,\" said the one--\"he is sti\n",
      "epoch 27\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 84s 418us/step - loss: 1.2937\n",
      "Generating with seed:  ot some day\n",
      "become interesting! but let us not be afraid! th\n",
      "epoch 28\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 81s 405us/step - loss: 1.2909\n",
      "Generating with seed:  nity, posit the question--truly a very living question--: to\n",
      "epoch 29\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 79s 392us/step - loss: 1.2884\n",
      "Generating with seed:  has to seek his way to the right and the belief\n",
      "only through\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1,30):\n",
    "    print('epoch', epoch)\n",
    "    model.fit(x,y, batch_size=128, epochs=1)\n",
    "    start_index = random.randint(0,len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('Generating with seed: ', generated_text)\n",
    "    \n",
    "    if(epoch%10 == 0 | epoch == 1):\n",
    "        for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "            print('Temperature: ', temperature)\n",
    "            #print(generated_text)\n",
    "            sys.stdout.write(generated_text)\n",
    "            for i in range(400):\n",
    "                sampled = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(generated_text):\n",
    "                    sampled[0, t, char_indices[char]] = 1\n",
    "                preds = model.predict(sampled,verbose=0)[0]\n",
    "                next_index = sample(preds, temperature)\n",
    "                next_char = chars[next_index]\n",
    "                generated_text += next_char\n",
    "                generated_text = generated_text[1:]\n",
    "\n",
    "                sys.stdout.write(next_char)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with seed:  t the virtuous and amiable try to convince him that it is no\n",
      "with temp:  0.2\n",
      "t the virtuous and amiable try to convince him that it is not to be still the sentiment of the same true the sense of the spirit of the spirit of the same to the same to the stone of the spirit of the strength of the same to the same true the consequently of the consequently of the same time the sentiment of the strength of the strength of the spirit of the same time the sense of his conduct and such a strength of the desire that the sentiment of the soul with temp:  0.5\n",
      "uch a strength of the desire that the sentiment of the soul is sense, and the world is to the strong to them a\n",
      "words of the farther--and the\n",
      "problem of the strength of the depthsom of the sense of mentory of the sureriops and profounder and feeling of the distinction of the spirit will be comparating the most hory of the fundamental and something itself to the story of his soul is absolutely something that still be allowndly he is the last nature of the brwith temp:  1\n",
      "hing that still be allowndly he is the last nature of the britnves,\" however is the shorth and finds, as prevai"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\installs\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls, not pastticality may tess, the seemnty in his gratil of \"inbiliary,\" really hatsled fred of other require in left as the blind has it is not propounners, we have tophical life will be not have first hatogical out of\n",
      "him growned, with revolity and perhaps, in the holour teach to the consensuality of i have\n",
      "with the counter--in the heartine of swith temp:  1.2\n",
      "nsensuality of i have\n",
      "with the counter--in the heartine of sufferings, effectance to sick,\n",
      "symbol tenting right\n",
      "so of\n",
      "revent actabilitity in ventable instinct. us the germany\n",
      "is proow inagance which worth traditsfellyess of the\n",
      "does riciss of sis of its verpodment, sere bora unilitians. only virtue artions,\n",
      "i also\n",
      "unteriors, the\n",
      "very preciseocy, things yeed,\n",
      "out regibor,\n",
      "for and should flore-efficably do \"greec(-pleasurable-irninations. and left and bond--"
     ]
    }
   ],
   "source": [
    "start_index = random.randint(0, len(text)-maxlen-1)\n",
    "seed = text[start_index:start_index+maxlen]\n",
    "\n",
    "def generateText(seed, paralength):\n",
    "    generated_text = seed\n",
    "    para = seed\n",
    "    print(\"with seed: \", generated_text)\n",
    "    for temperature in [0.2,0.5,1,1.2]:\n",
    "        print(\"with temp: \", temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "        for i in range(paralength):\n",
    "            sampled = np.zeros((1,maxlen, len(chars)))\n",
    "            for t,char in enumerate(generated_text):\n",
    "                sampled[0,t,char_indices[char]] = 1\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "            generated_text += next_char\n",
    "            para = generated_text\n",
    "            generated_text = generated_text[1:]\n",
    "            sys.stdout.write(next_char)\n",
    "    return para\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with seed:  he\n",
      "may have assumed the peaceable demeanour.\n",
      "\n",
      "132. one is pu\n",
      "with temp:  0.2\n",
      "he\n",
      "may have assumed the peaceable demeanour.\n",
      "\n",
      "132. one is put in the same to the same to the same and self-contradiction and conscience to the sentiment and conscience of the same to the sense of the sentiments, and also the sa"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\installs\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me and surerious and self-contemplation of the spirit of the desires of the spirit of the strength of the same to the same to the strengthess of the sentiment in the same time and seriousness and deceived and such a still consequentlwith temp:  0.5\n",
      "me and seriousness and deceived and such a still consequently of the will\n",
      "to a socialistic of the sureriops of the con and the case that is therefore, discovered the greater, or \"preciseory of the bearioure and depthsis of moral persons itself and decain the does which who forder believe to can so of the point of moral condition is does it consequently and more human conscience and innocreted the sense of life is individuals to the deal philosopher the samwith temp:  1\n",
      "sense of life is individuals to the deal philosopher the same problem is cursoric is oftiner without ever who self-faouned festines pringals puritity health; xerity to be ever man in suringers sciences of himself the\n",
      "genius and\n",
      "hese, to a still gives meaning of vanity, and things, the woman.\n",
      "\n",
      "\n",
      "noourable to those forcee eventryopies of this christeness self-old harding contrary, surperant sense in feeling\"--but sure, in ourselvest, from the\n",
      "grateful of goodwith temp:  1.2\n",
      "feeling\"--but sure, in ourselvest, from the\n",
      "grateful of good, so far childists: hetignisx; fund imposs to pridew--but skeming itself, also i proposition is good own\n",
      "exerciser rury most recredecc a disguise partial young itsee, or in for the attempts.)--the sentime of literariig is type develop easo-s. they fredsees us if a dervelcheth of vication of mi\n",
      "christianism accurte,\n",
      "origin enjoys; such remutide educated\n",
      "light bad quif nation for good), without bood"
     ]
    }
   ],
   "source": [
    "start_index = random.randint(0, len(text)-maxlen-1)\n",
    "seed = text[start_index:start_index+maxlen]\n",
    "\n",
    "generated_para = generateText(seed,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle \n",
    "  \n",
    "# Save the trained model as a pickle string. \n",
    "saved_model = pickle.dumps(model) \n",
    "  \n",
    "# Load the pickled model \n",
    "loaded_from_pickle = pickle.loads(saved_model) \n",
    "\n",
    "sampled = np.zeros((1,maxlen, len(chars)))\n",
    "for t,char in enumerate(generated_text):\n",
    "    sampled[0,t,char_indices[char]] = 1\n",
    "# Use the loaded pickled model to make predictions \n",
    "preds = loaded_from_pickle.predict(sampled, verbose=0)[0]\n",
    "next_index = sample(preds, temperature)\n",
    "next_char = chars[next_index]\n",
    "\n",
    "print(next_char)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
